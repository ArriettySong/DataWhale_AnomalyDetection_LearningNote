[TOC]

# 异常检测概述

## 1. 什么是异常检测

> #### 异常的类别
>
> **点异常**：指的是少数个体实例是异常的，大多数个体实例是正常的，例如正常人与病人的健康指标；
>
> **上下文异常**：又称上下文异常，指的是在特定情境下个体实例是异常的，在其他情境下都是正常的，例如在特定时间下的温度突然上升或下降，在特定场景中的快速信用卡交易；
>
> **群体异常**：指的是在群体集合中的个体实例出现异常的情况，而该个体实例自身可能不是异常，例如社交网络中虚假账号形成的集合作为群体异常子集，但子集中的个体节点可能与真实账号一样正常。

> ####  异常检测场景
>
> * **故障检测** (点异常，工业)
>
> * **物联网异常检测**
>
> * **欺诈检测**（点异常，群体异常，在有利可图的业务场景非常常见）
>
> * **工业异常检测**（上下文异常，电力 .etc）
>
> * **时间序列异常检测**（上下文异常，诸多场景）
>
> * **视频异常检测**（上下文异常）
>
> * **日志异常检测**（上下文异常）
>
> * **医疗日常检测**（点异常）
>
> * **网络入侵检测**（点异常，群体异常）



## 2、异常检测常用方法

### 2.1 传统方法

#### 2.1.1 基于统计学的方法

> 统计学方法对数据的正常性做出假定。**它们假定正常的数据对象由一个统计模型产生，而不遵守该模型的数据是异常点。**统计学方法的有效性高度依赖于对给定数据所做的统计模型假定是否成立。
>
> 异常检测的统计学方法的一般思想是：学习一个拟合给定数据集的生成模型，然后识别该模型低概率区域中的对象，把它们作为异常点。

#### 2.1.2 线性模型

<font color="red">线性模型是可以单独解决问题的一种方法，还是只是用来提高数据的计算性能，并且缓解"高维灾难"的方法？</font>

<font color="green">是一种方法，通过重构误差实现</font>

#### 2.1.3 基于相似度的方法

>  这类算法适用于数据点的聚集程度高、离群点较少的情况。同时，因为相似度算法通常需要对每一个数据分别进行相应计算，所以这类算法**通常计算量大，不太适用于数据量大、维度高的数据**。
>
> <font color="red">基于此，基于相似度的方法在大数据量的业务场景，适用性会比较有限吧？</font>
>
> 基于相似度的检测方法大致可以分为三类： 
>
> - 基于集群（簇）的检测，如DBSCAN等聚类算法。 
>   &emsp;&emsp;聚类算法是将数据点划分为一个个相对密集的“簇”，而那些不能被归为某个簇的点，则被视作离群点。这类算法对簇个数的选择高度敏感，数量选择不当可能造成较多正常值被划为离群点或成小簇的离群点被归为正常。因此对于每一个数据集需要设置特定的参数，才可以保证聚类的效果，在数据集之间的通用性较差。聚类的主要目的通常是为了寻找成簇的数据，而将异常值和噪声一同作为无价值的数据而忽略或丢弃，在专门的异常点检测中使用较少。 
>   &emsp;&emsp;聚类算法的优缺点： 
>   （1）能够较好发现小簇的异常； 
>   （2）通常用于簇的发现，而对异常值采取丢弃处理，对异常值的处理不够友好； 
>   （3）产生的离群点集和它们的得分可能非常依赖所用的簇的个数和数据中离群点的存在性； 
>   （4）聚类算法产生的簇的质量对该算法产生的离群点的质量影响非常大。
> - 基于距离的度量，如k近邻算法。 
>   &emsp;&emsp;k近邻算法的基本思路是对每一个点，计算其与最近k个相邻点的距离，通过距离的大小来判断它是否为离群点。在这里，离群距离大小对k的取值高度敏感。如果k太小（例如1），则少量的邻近离群点可能导致较低的离群点得分；如果k太大，则点数少于k的簇中所有的对象可能都成了离群点。为了使模型更加稳定，距离值的计算通常使用k个最近邻的平均距离。 
>   &emsp;&emsp;k近邻算法的优缺点： 
>   （1）简单； 
>   （2）基于邻近度的方法需要O(m2)时间，大数据集不适用； 
>   （3）对参数的选择敏感；
>   （4）不能处理具有不同密度区域的数据集，因为它使用全局阈值，不能考虑这种密度的变化。    
> - 基于密度的度量，如**LOF（局部离群因子）算法**。
>   &emsp;&emsp;局部离群因子（LOF）算法与k近邻类似，不同的是它以相对于其邻居的局部密度偏差而不是距离来进行度量。它将相邻点之间的距离进一步转化为“邻域”，从而得到邻域中点的数量（即密度），认为密度远低于其邻居的样本为异常值。 
>   LOF（局部离群因子）算法的优缺点： 
>   （1）给出了对离群度的定量度量； 
>   （2）能够很好地处理不同密度区域的数据； 
>   （3）对参数的选择敏感。     



### 2.2 集成方法

> 集成是提高数据挖掘算法精度的常用方法。集成方法将多个算法或多个基检测器的输出结合起来。其基本思想是一些算法在某些子集上表现很好，一些算法在其他子集上表现很好，然后集成起来使得输出更加鲁棒。集成方法与基于子空间方法有着天然的相似性，子空间与不同的点集相关，而集成方法使用基检测器来探索不同维度的子集，将这些基学习器集合起来。

**feature bagging **：

**孤立森林**：

### 2.3 机器学习（有监督）

xgboost、gbdt等





## 3. 异常检测在招聘业务风控的应用场景及方案

### 3.1 应用场景

作为业务风控方，我们的日常工作中有诸多场景可以使用异常检测算法策略。如：

- **BC端账号行为异常**（包括单项行为和整体行为）(点异常、上下文异常、群体异常)

> 挖掘群体中极度少数的个体实例，是点异常
>
> 挖掘账号某天/某个时间段/某个时间点的行为突变，是上下文异常
>
> 挖掘欺诈账号团体，是群体异常。

- 实时服务出错异常检测（上下文异常）
- 文本内容异常检测（点异常）

> 文本组成结构与众不同，是否有必要用异常检测？还是直接有监督？可以试试

- 通话异常检测（精细：上下文异常，粗略：点异常）

> 性别、求职状态频繁变化



### 3.2 适用的算法

招聘业务风控的场景中，大部分业务行为，比如：发布、浏览、点击、投递、下载等数据量级都是超大，仅仅在小部分业务场景，如：投诉、通话等场景中，数据量级较小。所以可解决大数据量级的算法的学习优先级较高。

IForest：

HBOS：









原文见：https://github.com/datawhalechina/team-learning-data-mining/blob/master/AnomalyDetection/%E4%B8%80%E3%80%81%E6%A6%82%E8%BF%B0.md



