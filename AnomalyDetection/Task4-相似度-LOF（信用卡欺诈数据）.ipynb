{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOF算法实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyod\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印cell中的多个输出\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据源来自kaggle的信用卡欺诈数据 https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "path = 'dataverse_files/'\n",
    "data = pd.read_csv(path+r\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,data.columns != \"Class\"]\n",
    "y = data.iloc[:,data.columns == \"Class\"]\n",
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.lof import LOF\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOF(algorithm='auto', contamination=0.017271035911117352, leaf_size=30,\n",
       "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=20, p=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_name=\"lof\"\n",
    "clf=LOF(contamination=492/28487)\n",
    "# clf=LOF()\n",
    "clf.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.labels_\n",
    "y_train_scores = clf.decision_scores_\n",
    "y_test_pred = clf.predict(Xtest)\n",
    "y_test_scores = clf.decision_function(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On Training Data:\n",
      "lof ROC:0.7313, precision @ rank n:0.0323\n",
      "\n",
      "On Test Data:\n",
      "lof ROC:0.7445, precision @ rank n:0.0464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016260162601626018"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    199023\n",
      "           1       0.02      0.16      0.03       341\n",
      "\n",
      "    accuracy                           0.98    199364\n",
      "   macro avg       0.51      0.57      0.51    199364\n",
      "weighted avg       1.00      0.98      0.99    199364\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85292\n",
      "           1       0.01      0.12      0.02       151\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.51      0.55      0.51     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate and print the results\n",
    "print(\"\\nOn Training Data:\")\n",
    "evaluate_print(clf_name, Ytrain, y_train_scores)\n",
    "print(\"\\nOn Test Data:\")\n",
    "evaluate_print(clf_name, Ytest, y_test_scores)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(Ytrain, y_train_pred, average='binary') \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Ytrain, y_train_pred))\n",
    "print(classification_report(Ytest, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
